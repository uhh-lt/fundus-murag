services:
  fundus-murag-ml:
    image: p0w3r/fundus-murag-ml:latest
    user: ${UID:-1000}:${GID:-1000}
    profiles:
      - fundusml
    ports:
      - "${FUNDUS_ML_EXPOSED}:8000"
    volumes:
      - ./models_cache:/models_cache
    restart: on-failure:0
    environment:
      - TRANSFORMERS_CACHEe=/models_cache
      - HUGGINGFACE_HUB_CACHE=/models_cache
      - TORCH_HOME=/models_cache
      - FUNDUS_ML_DEV_MODE=${FUNDUS_ML_DEV_MODE}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "1" ]
              capabilities: [ gpu ]

  fundus-murag-ui:
    image: p0w3r/fundus-murag-ui:latest
    user: ${UID:-1000}:${GID:-1000}
    profiles:
      - fundusui
    ports:
      - "${FUNDUS_UI_EXPOSED}:8080"
    volumes:
      - ../data:/data
      - ./fundus-murag-ui-logs:/logs
    restart: on-failure:0
    environment:
      - FUNDUS_CONFIG_FILE=config.prod.yaml

  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.26.5
    user: ${UID:-1000}:${GID:-1000}
    profiles:
      - weaviate
    command:
      - --host
      - 0.0.0.0
      - --port
      - "8080"
      - --scheme
      - http
    ports:
      - "${WEAVIATE_HTTP_EXPOSED}:8080"
      - "${WEAVIATE_GRPC_EXPOSED}:50051"
    volumes:
      - ./weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      DEFAULT_VECTORIZER_MODULE: "none"
      ENABLE_MODULES: ""
      CLUSTER_HOSTNAME: "node1"

  weaviate-dev:
    image: cr.weaviate.io/semitechnologies/weaviate:1.26.5
    user: ${UID:-1000}:${GID:-1000}
    profiles:
      - weaviate-dev
    command:
      - --host
      - 0.0.0.0
      - --port
      - "8080"
      - --scheme
      - http
    ports:
      - "${WEAVIATE_HTTP_EXPOSED}:8080"
      - "${WEAVIATE_GRPC_EXPOSED}:50051"
    volumes:
      - ./weaviate_data-dev:/var/lib/weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      DEFAULT_VECTORIZER_MODULE: "none"
      ENABLE_MODULES: ""
      CLUSTER_HOSTNAME: "node1"

  vllm:
    image: vllm/vllm-openai:nightly
    profiles:
      - local-vlm
    entrypoint: python3
    command:
      - -m
      - vllm.entrypoints.openai.api_server
      - --port=8000
      - --host=0.0.0.0
      - --model mistralai/Pixtral-12B-2409
      - --limit-mm-per-prompt 'image=10'
      - --max-model-len 32768
      - --tokenizer-mode mistral
      - --load-format mistral
      - --config-format mistral"
    # --enable-auto-tool-choice --tool-call-parser mistral --tokenizer-mode mistral --load-format mistral --config-format mistral" --chat-template /workspace/templates/tool_chat_template_mistral.jinja"
    env_file:
      - .env
    ports:
      - "${VLLM_EXPOSED}:8000"
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - LOG_LEVEL=DEBUG
    volumes:
      - ./cache:/workspace/.cache
      - ./templates:/workspace/templates
    restart: always
    shm_size: "64gb"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://0.0.0.0:8000/v1/models" ]
      interval: 30s
      timeout: 5s
      retries: 20
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "1" ]
              capabilities: [ gpu ]
